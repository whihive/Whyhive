# -*- coding: utf-8 -*-
"""sentiment_analysis_mahesh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XTiNfR7OVQidSaQ3wOimBhwemtAjXH9j
"""

import numpy as np
import os
import sys
import librosa
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from keras.layers import LSTM
from keras.layers import Bidirectional
from keras.layers import TimeDistributed
from keras.models import Sequential
from keras.layers import Dense, Activation,Dropout, Flatten, Embedding
import pickle
import IPython.display as ipd

import librosa
import librosa.display
import matplotlib.pyplot as plt

#Ipython display library is used to analyse audio samples instantly

ipd.Audio('/home/shiny/Downloads/107620_256618_bundle_archive/Actor_01/03-01-01-01-01-01-01.wav')

# Librosa helps to visualize the audio signals and also do the feature extractions 
#in it using different signal processing techniques.

#We have plotted a waveplot and displayed it.

#check this link for more on Librosa:https://medium.com/@patrickbfuller/librosa-a-python-audio-libary-60014eeaccfb

filename = '/home/shiny/Downloads/107620_256618_bundle_archive/Actor_01/03-01-01-01-01-01-01.wav'
plt.figure(figsize=(12,4))
data,sample_rate = librosa.load(filename)
_ = librosa.display.waveplot(data,sr=sample_rate)
ipd.Audio(filename)
print(sample_rate)
print(data)

#Check this to know MFCC : https://en.wikipedia.org/wiki/Mel-frequency_cepstrum

#Check this out to know on MFCC:https://musicinformationretrieval.com/mfcc.html

#check this out too: 
#https://towardsdatascience.com/how-i-understood-what-features-to-consider-while-training-audio-files-eedfb6e9002b

librosa_audio, librosa_sample_rate = librosa.load(filename) 

mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc=40)
print(mfccs.shape)

#we are defining out method "extract_features" and we bound it with try and catch methods.

#"librosa.load" method gives you audio-data and sample rate of each sound-file

#Then,we extract mfcc features by giving arguements audio,sample rate, and number of mfcc

#Then we scaled up and take mean of the extracted mfcc along axis=0(row)

def extract_features(file_name):
   
    try:
        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
        mfccsscaled = np.mean(mfccs.T,axis=0)
        
        
    except Exception as e:
        print("Error encountered while parsing file: ", file_name)
        return None 
     
    return mfccsscaled

print(mfccs.shape)

#The data set has 24 folders, each folder is dedicated to each artist with 60 samples each.
#Total samples equlas 24*60 = 1440

#We first give path to the parent directory

#We retrieve list of folders by using "os.listdir"

parentdir='/home/shiny/Downloads/107620_256618_bundle_archive'

actors_fold=os.listdir(parentdir)

#So here, we move into each folder and take out audio samples and extract festures for respective audio sample.

#We save those features in "Features[]"along with class label.

#We get class label from the name of the audio-file.

#Example : 03-01-04-02-01-02-02.wav , here classlabel is '04'

features=[]
for i in actors_fold:
    
    voice_clips=os.listdir(parentdir+"/"+i)
    for j in voice_clips:
        data=extract_features(parentdir+"/"+i+"/"+j)
        class_label=j[7:8]
        
        features.append([data,class_label])

#convert features into  dataframe and give names to columns

import pandas as pd
featuresdf = pd.DataFrame(features, columns=['feature','class_label'])

#Display features data frame

featuresdf

#Convert features into numpy arrays

# Convert class_label into numpy arrays

X_data = np.array(featuresdf.feature.tolist())
Y_data = np.array(featuresdf.class_label.tolist())

from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical

#define LabelEncoder object

#fit_trasnform the class_label

#To know more on Label encoder: https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/#:~:text=Label%20Encoding%20refers%20to%20converting,structured%20dataset%20in%20supervised%20learning.

LE = LabelEncoder()
Y_LE = to_categorical(LE.fit_transform(Y_data))

Y_LE

#Split the data set

from sklearn.model_selection import train_test_split 

X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X_data,Y_LE, test_size=0.2, random_state = 42)

#check the shape of split data set

print(X_TRAIN[1].shape)
print(Y_TRAIN.shape)
print(X_TEST.shape)
print(Y_TEST.shape)

#for more on %store: https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html

#It is generally used to store the data and to recall it later in the other notebooks as well

# Commented out IPython magic to ensure Python compatibility.
# %store X_TRAIN 
# %store X_TEST 
# %store Y_TRAIN
# %store Y_TEST
# %store Y_LE
# %store LE

#Retrieving stored data

# Commented out IPython magic to ensure Python compatibility.
# %store -r X_TRAIN 
# %store -r X_TEST 
# %store -r Y_TRAIN
# %store -r Y_TEST
# %store -r Y_LE
# %store -r LE

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn import metrics

#checking number of labels

num_labels = Y_LE.shape

print(num_labels)

#Build the model

#It is a sequential model

#For the first layer , we input "X_TRAIN.shape[1]" i.e (40,) which is the output of first layer and "input_dim" is also the same

#For more on dropout : https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/

#We are using 'relu' activation function for the hidden layers and 'softmax' for the output layer.

model=Sequential()

model.add(Dense(X_TRAIN.shape[1],input_dim=X_TRAIN.shape[1],init='normal',activation='relu'))

model.add(Dense(400,init='normal',activation='relu'))

model.add(Dropout(0.2))

model.add(Dense(200,init='normal',activation='relu'))

model.add(Dropout(0.2))

model.add(Dense(100,init='normal',activation='relu'))

model.add(Dropout(0.2))

model.add(Dense(Y_TRAIN.shape[1],init='normal',activation='softmax'))

model.summary()

#We are using 'categorical_crossentropy' for loss function, 'adagrad' for optimization, ['accuracy'] for metrics

model.compile(loss = 'categorical_crossentropy',optimizer='adagrad',metrics=['accuracy'])

#calculate model accuracy score prior to training

model.summary()

score = model.evaluate(X_TEST,Y_TEST, verbose=0)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

#Select number of epochs

#select batch_size

#Save best weights in the filepath given by calling ModelCheckpoint method

#Fit the model

#Save the model in the filepath given

#calculate the time taken for the model to get trained

from keras.callbacks import ModelCheckpoint 
from datetime import datetime 

num_epochs = 300
num_batch_size = 10

checkpointer = ModelCheckpoint(filepath='/home/shiny/Desktop/weights_best_senti_mahesh_5.h5', 
                               verbose=1, save_best_only=True)
start = datetime.now()

model.fit(X_TRAIN,Y_TRAIN,validation_data=(X_TEST,Y_TEST), batch_size=num_batch_size, epochs=num_epochs,callbacks=[checkpointer], verbose=1)

model.save('testmlpnew_final_mahesh_5.h5')
duration = datetime.now() - start
print("Training completed in time: ", duration)

#Evaluate the accuracy scores for training and testing set

# Evaluating the model on the training and testing set
score = model.evaluate(X_TRAIN,Y_TRAIN, verbose=0)
print("Training Accuracy: ", score[1])

score_test = model.evaluate(X_TEST,Y_TEST, verbose=0)
print("Testing Accuracy: ",score_test[1])

#Testing the model by individual samples

#Define the extract_features function again

import librosa 
import numpy as np 

def extract_feature(file_name):
   
    try:
        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)
        mfccsscaled = np.mean(mfccs.T,axis=0)
        
    except Exception as e:
        print("Error encountered while parsing file: ", file)
        return None, None

    return np.array([mfccsscaled])

#Define print_prediction method

#Give the names of the labels

#Extract features of the selected audio-file and save them in prediction_feature

#Then predict the class using "model.predict_classes" using the extracted features

#Then,inverse transform the predicted_vector by using the label encoder wew defined prior

#since,the index starts from 0 , and the class_label are from 1-8 we substract '1'

#print the class name

#Then, we predict probability from the predicted feature and do the same for every class for respective audio-file 
#and print them.

def print_prediction(file_name):
    
    feature_names=["neutral","calm","happy","sad","angry","fearful","disgust","surprised"]
    prediction_feature = extract_feature(file_name) 

    predicted_vector = model.predict_classes(prediction_feature)
    predicted_class = LE.inverse_transform(predicted_vector)
    class_num=int(predicted_class[0])-1
    print("The predicted class is: "+ feature_names[class_num])


    predicted_proba_vector = model.predict_proba(prediction_feature) 
    predicted_proba = predicted_proba_vector[0]
    for i in range(len(predicted_proba)): 
        category = LE.inverse_transform(np.array([i]))
        print(category[0], "\t\t : ", format(predicted_proba[i], '.4f') )

filename = '/home/shiny/Downloads/107620_256618_bundle_archive/Actor_02/03-01-04-02-01-02-02.wav' 
print_prediction(filename)

